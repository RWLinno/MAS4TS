# MAS4TS å½“å‰å®ç°çŠ¶æ€

## âœ… å·²å®Œæˆ

### 1. æ ¸å¿ƒæ¶æ„
- âœ… `models/MAS4TS.py`: çœŸæ­£è°ƒç”¨Multi-Agentç³»ç»Ÿï¼Œä¸æ˜¯ç®€å•çš„ç¥ç»ç½‘ç»œ
- âœ… `src/agents/manager_agent.py`: å®Œæ•´çš„4-Agentæ‰§è¡Œè®¡åˆ’
- âœ… `src/agents/base_agent_ts.py`: AgentåŸºç±»
- âœ… `src/base/processor.py`: æ•°æ®é¢„å¤„ç†å™¨

### 2. Multi-Agentæµç¨‹ï¼ˆå·²è§„åˆ’ï¼‰

```
è¾“å…¥æ•°æ® (x_enc)
    â†“
[Stage 1] Data Analyzer Agent
    â†’ åˆ†ææ•°æ®è¶‹åŠ¿ã€ç»Ÿè®¡ä¿¡æ¯
    â†’ ç”Ÿæˆplotå›¾ (ä¿å­˜åˆ° ./visualizations/data_analysis/)
    â†’ è¾“å‡º: data_features, plot_path, statistics_text
    â†“
[Stage 2] Visual Anchor Agent
    â†’ è¯»å–plotå›¾
    â†’ è°ƒç”¨VLM (Qwen-VL) åˆ†æå›¾åƒ
    â†’ ç”Ÿæˆé”šç‚¹å’Œç½®ä¿¡åŒºé—´
    â†’ ä¿å­˜å¸¦æ ‡æ³¨çš„å›¾ç‰‡
    â†’ è¾“å‡º: visual_anchors, anchor_image_path
    â†“
[Stage 3] Numerical Adapter Agent
    â†’ ä½¿ç”¨LLMè¿›è¡Œæ•°å€¼æ¨ç†
    â†’ å¹¶å‘è°ƒç”¨3ä¸ªæ¨¡å‹ (qwen-7b, qwen-14b, qwen-72b)
    â†’ ensembleç»“æœ
    â†’ è¾“å‡º: numerical_predictions, confidence_intervals
    â†“
[Stage 4] Task Executor Agent
    â†’ æ•´åˆæ‰€æœ‰ä¿¡æ¯
    â†’ æ ¹æ®ä»»åŠ¡ç±»å‹è¾“å‡ºæœ€ç»ˆç»“æœ
    â†’ è¾“å‡º: final_predictions
    â†“
æœ€ç»ˆè¾“å‡º
```

## ğŸš§ éœ€è¦å®Œæˆçš„å®ç°

### 1. Data Analyzer Agent - æ·»åŠ å¯è§†åŒ–åŠŸèƒ½

**æ–‡ä»¶**: `src/agents/data_analyzer.py`

**éœ€è¦æ·»åŠ **:
```python
import matplotlib.pyplot as plt
import os
from pathlib import Path

async def process(self, input_data):
    # ... ç°æœ‰ä»£ç  ...
    
    # æ·»åŠ å¯è§†åŒ–
    if task == 'full_analysis_with_plot':
        plot_path = self._generate_plot(data, batch_idx=0)
        statistics_text = self._generate_statistics_text(features)
        result['plot_path'] = plot_path
        result['statistics_text'] = statistics_text

def _generate_plot(self, data, batch_idx=0):
    """ç”Ÿæˆæ—¶åºplotå›¾"""
    save_dir = Path('./visualizations/data_analysis/')
    save_dir.mkdir(parents=True, exist_ok=True)
    save_path = save_dir / f'batch_{batch_idx}_analysis.png'
    
    fig, ax = plt.subplots(figsize=(12, 6))
    data_np = data[0].cpu().numpy()  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    for i in range(min(3, data.shape[2])):
        ax.plot(data_np[:, i], label=f'Feature {i}', linewidth=2)
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_xlabel('Time Steps')
    ax.set_ylabel('Value')
    ax.set_title('Time Series Data Analysis')
    
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    return str(save_path)

def _generate_statistics_text(self, features):
    """ç”Ÿæˆç»Ÿè®¡æè¿°"""
    text = "Time Series Statistics:\n"
    text += f"- Mean: {features['mean'].mean().item():.4f}\n"
    text += f"- Std: {features['std'].mean().item():.4f}\n"
    text += f"- Min: {features['min'].mean().item():.4f}\n"
    text += f"- Max: {features['max'].mean().item():.4f}\n"
    text += f"- Trend Slope: {features['trend'].mean().item():.6f}\n"
    return text
```

### 2. Visual Anchor Agent - é›†æˆVLM

**æ–‡ä»¶**: `src/agents/visual_anchor.py`

**éœ€è¦æ·»åŠ **:
```python
from PIL import Image
import json

# åœ¨__init__ä¸­æ·»åŠ VLMé…ç½®
def __init__(self, config):
    super().__init__("VisualAnchorAgent", config)
    self.use_vlm = config.get('use_vlm', False)
    self.use_eas = config.get('use_eas', False)
    self.vlm_model_name = config.get('vlm_model', 'qwen-vl')
    
    if self.use_vlm and not self.use_eas:
        self._init_local_vlm()

def _init_local_vlm(self):
    """åˆå§‹åŒ–æœ¬åœ°VLMæ¨¡å‹"""
    try:
        from transformers import AutoModelForCausalLM, AutoTokenizer
        self.vlm_model = AutoModelForCausalLM.from_pretrained(
            "Qwen/Qwen-VL-Chat",
            device_map="auto",
            trust_remote_code=True
        ).eval()
        self.vlm_tokenizer = AutoTokenizer.from_pretrained(
            "Qwen/Qwen-VL-Chat",
            trust_remote_code=True
        )
        self.log_info("VLM model loaded successfully")
    except Exception as e:
        self.log_error(f"Failed to load VLM: {e}")
        self.use_vlm = False

async def _extract_semantic_priors(self, plot_path, statistics_text, task):
    """ä½¿ç”¨VLMæå–è¯­ä¹‰å…ˆéªŒ"""
    if not self.use_vlm:
        return self._extract_rule_based_priors(data, task)
    
    prompt = f"""Analyze this time series plot for {task} task.

{statistics_text}

Based on the plot, provide:
1. Trend direction (increasing/decreasing/stable)
2. Volatility level (low/medium/high)
3. Confidence interval width (narrow/medium/wide)
4. Key anchor points for future predictions

Format as JSON."""

    if self.use_eas:
        response = await self._call_eas_vlm(plot_path, prompt)
    else:
        image = Image.open(plot_path)
        query = self.vlm_tokenizer.from_list_format([
            {'image': plot_path},
            {'text': prompt}
        ])
        response, _ = self.vlm_model.chat(
            self.vlm_tokenizer, 
            query=query, 
            history=None
        )
    
    return self._parse_vlm_response(response)
```

### 3. Numerical Adapter Agent - å¹¶å‘LLMæ¨ç†

**æ–‡ä»¶**: `src/agents/numerologic_adapter.py`

**éœ€è¦æ·»åŠ **:
```python
import asyncio

async def process(self, input_data):
    # ... ç°æœ‰ä»£ç  ...
    
    if input_data.get('use_parallel_llm', False):
        num_models = input_data.get('num_llm_models', 3)
        predictions = await self._parallel_llm_inference(
            visual_anchors, 
            data_features,
            num_models
        )
        result['numerical_predictions'] = predictions

async def _parallel_llm_inference(self, anchors, features, num_models=3):
    """å¹¶å‘è°ƒç”¨å¤šä¸ªLLM"""
    prompt = self._build_numerical_reasoning_prompt(anchors, features)
    
    tasks = []
    models = ['qwen-7b', 'qwen-14b', 'qwen-72b'][:num_models]
    
    for model_name in models:
        tasks.append(self._call_single_llm(model_name, prompt))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # è¿‡æ»¤é”™è¯¯å¹¶ensemble
    valid_results = [r for r in results if not isinstance(r, Exception)]
    if valid_results:
        return self._ensemble_predictions(valid_results)
    else:
        # Fallback
        return self._rule_based_prediction(anchors, features)

def _build_numerical_reasoning_prompt(self, anchors, features):
    """æ„å»ºLLMæ¨ç†prompt"""
    prompt = f"""Task: Time series numerical reasoning

Visual Anchors:
- Expected range: [{anchors['lower_bound']}, {anchors['upper_bound']}]
- Trend direction: {anchors.get('trend_direction', 'unknown')}
- Anchor points: {anchors.get('key_points', [])}

Data Features:
- Mean: {features['mean']}
- Std: {features['std']}
- Trend slope: {features['trend']}

Perform numerical reasoning to:
1. Refine the prediction range
2. Identify specific anchor values
3. Provide confidence scores

Output JSON format:
{{
  "predictions": [value1, value2, ...],
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation"
}}"""
    return prompt
```

### 4. Task Executor Agent - æ•´åˆæ‰€æœ‰è¾“å‡º

**æ–‡ä»¶**: `src/agents/task_executor.py`

**å·²åŸºæœ¬å®Œæˆ**ï¼Œéœ€è¦ç¡®ä¿èƒ½æ¥æ”¶å¹¶ä½¿ç”¨ï¼š
- `numerical_predictions` from Numerical Adapter
- `visual_anchors` from Visual Anchor
- `confidence_intervals` from Numerical Adapter

## ğŸ“ Promptè®¾è®¡ï¼ˆå·²å®Œæˆï¼‰

è¯¦è§ `MULTI_AGENT_IMPLEMENTATION.md`

## ğŸ¯ è¿è¡Œæ–¹å¼

### ç®€å•æ¨¡å¼ï¼ˆä¸ä½¿ç”¨VLM/LLMï¼‰
```bash
bash src/scripts/test_all_tasks.sh
```
- ä½¿ç”¨rule-basedæ–¹æ³•æ›¿ä»£VLM/LLM
- é€‚åˆå¿«é€Ÿæµ‹è¯•

### å®Œæ•´æ¨¡å¼ï¼ˆä½¿ç”¨æœ¬åœ°VLMï¼‰
```bash
python run.py \
  --model MAS4TS \
  --task_name long_term_forecast \
  --use_vlm \
  --vlm_model Qwen/Qwen-VL-Chat \
  --data ETTh1 \
  --seq_len 96 \
  --pred_len 96
```

### å®Œæ•´æ¨¡å¼ï¼ˆä½¿ç”¨EASåœ¨çº¿æœåŠ¡ï¼‰
```bash
python run.py \
  --model MAS4TS \
  --use_vlm \
  --use_eas \
  --eas_url https://your-endpoint.com \
  ...
```

## ğŸ“Š å¯è§†åŒ–è¾“å‡º

æ‰€æœ‰ä¸­é—´ç»“æœä¼šä¿å­˜åˆ°ï¼š
```
./visualizations/
â”œâ”€â”€ data_analysis/
â”‚   â”œâ”€â”€ batch_0_analysis.png       # Data Analyzerè¾“å‡º
â”‚   â””â”€â”€ batch_0_statistics.txt
â”œâ”€â”€ visual_anchors/
â”‚   â”œâ”€â”€ batch_0_anchors.png        # Visual Anchorè¾“å‡º
â”‚   â””â”€â”€ batch_0_anchors.json
â””â”€â”€ numerical_reasoning/
    â””â”€â”€ batch_0_predictions.json   # Numerical Adapterè¾“å‡º
```

## ğŸ”§ ä¸‹ä¸€æ­¥å·¥ä½œ

1. **å®ç°Data Analyzerå¯è§†åŒ–** (30åˆ†é’Ÿ)
   - æ·»åŠ `_generate_plot()`æ–¹æ³•
   - æ·»åŠ `_generate_statistics_text()`æ–¹æ³•

2. **å®ç°Visual Anchor VLMé›†æˆ** (1å°æ—¶)
   - æ·»åŠ æœ¬åœ°Qwen-VLåŠ è½½
   - æ·»åŠ EASå®¢æˆ·ç«¯
   - å®ç°promptè°ƒç”¨

3. **å®ç°Numerical Adapterå¹¶å‘LLM** (1å°æ—¶)
   - å¹¶å‘è°ƒç”¨å¤šä¸ªæ¨¡å‹
   - Ensembleç­–ç•¥
   - Fallbackæœºåˆ¶

4. **æµ‹è¯•å®Œæ•´æµç¨‹** (30åˆ†é’Ÿ)
   - è¿è¡Œæµ‹è¯•è„šæœ¬
   - æ£€æŸ¥å¯è§†åŒ–è¾“å‡º
   - éªŒè¯ç»“æœå‡†ç¡®æ€§

## ğŸ’¡ è®¾è®¡ç†å¿µ

**ä¸ºä»€ä¹ˆä½¿ç”¨Multi-Agentè€Œä¸æ˜¯å•ä¸€æ¨¡å‹ï¼Ÿ**

1. **ä¸“ä¸šåˆ†å·¥**: æ¯ä¸ªAgentä¸“æ³¨äºä¸€ä¸ªå­ä»»åŠ¡
2. **å¯è§£é‡Šæ€§**: æ¯ä¸ªæ­¥éª¤çš„ä¸­é—´ç»“æœå¯è§†åŒ–
3. **çµæ´»æ€§**: å¯ä»¥å•ç‹¬æ›¿æ¢/ä¼˜åŒ–ä»»ä½•Agent
4. **å¹¶å‘æ€§**: Numerical Adapterå¹¶å‘è°ƒç”¨3ä¸ªLLMï¼Œæé€Ÿ3å€
5. **å‡†ç¡®æ€§**: VLM+LLM ensembleæå‡é¢„æµ‹ç²¾åº¦

**æ ¸å¿ƒåˆ›æ–°ç‚¹**:
- ğŸ¯ **Visual Anchoring**: å°†æ—¶åºè½¬ä¸ºå›¾åƒï¼Œç”¨VLMç†è§£æ¨¡å¼
- ğŸ§® **Numerical Reasoning**: ç”¨LLM ensembleè¿›è¡Œç²¾ç¡®æ•°å€¼æ¨ç†
- ğŸ¤ **Agent Collaboration**: 4ä¸ªAgentåä½œï¼Œä¸æ˜¯ç®€å•pipeline

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `MULTI_AGENT_IMPLEMENTATION.md` - è¯¦ç»†å®ç°æŒ‡å—
- `QUICK_START.md` - å¿«é€Ÿå¼€å§‹
- `BUG_FIX_SUMMARY.md` - Bugä¿®å¤è®°å½•
- `README.md` - é¡¹ç›®æ€»è§ˆ

