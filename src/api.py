#!/usr/bin/env python3
"""
OnCallAgent FastAPIæœåŠ¡
æä¾›REST APIæ¥å£ç”¨äºæ™ºèƒ½è¿ç»´é—®ç­”
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
import json
import base64

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥OnCallAgentæ ¸å¿ƒæ¨¡å—
try:
    from main import process_request
    print("âœ… Successfully imported process_request from main")
except ImportError as e:
    print(f"âŒ Failed to import process_request: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("OnCallAgent.API")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="OnCallAgent API",
    description="æ™ºèƒ½è¿ç»´é—®ç­”ç³»ç»ŸAPIæ¥å£",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ¨¡å‹
class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="ç”¨æˆ·æŸ¥è¯¢å†…å®¹")
    image: Optional[str] = Field(None, description="å›¾ç‰‡base64ç¼–ç ï¼ˆå¯é€‰ï¼‰")
    context: Dict[str, Any] = Field(default_factory=dict, description="ä¸Šä¸‹æ–‡ä¿¡æ¯")
    model: str = Field("Qwen/Qwen2.5-VL-7B-Instruct", description="ä½¿ç”¨çš„æ¨¡å‹")
    type: str = Field("offline", description="æ¨¡å‹ç±»å‹")
    device: str = Field("cpu", description="è¿è¡Œè®¾å¤‡")
    agents: Dict[str, Dict[str, bool]] = Field(
        default_factory=lambda: {
            "route_agent": {"enabled": True},
            "visual_analysis_agent": {"enabled": True},
            "metrics_analysis_agent": {"enabled": True},
            "log_analysis_agent": {"enabled": True},
            "knowledge_agent": {"enabled": True},
            "comprehensive_agent": {"enabled": True},
            "retrieval_agent": {"enabled": True},
            "search_agent": {"enabled": True}
        },
        description="å¯ç”¨çš„æ™ºèƒ½ä½“é…ç½®"
    )

class QueryResponse(BaseModel):
    """æŸ¥è¯¢å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    answer: str = Field(..., description="å›ç­”å†…å®¹")
    confidence: float = Field(..., description="ç½®ä¿¡åº¦")
    agent_used: str = Field(..., description="ä½¿ç”¨çš„æ™ºèƒ½ä½“")
    processing_time: float = Field(..., description="å¤„ç†æ—¶é—´")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="å…ƒæ•°æ®")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")

# APIè·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return {
        "message": "OnCallAgent APIæœåŠ¡",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        import torch
        gpu_available = torch.cuda.is_available()
        gpu_count = torch.cuda.device_count() if gpu_available else 0
        
        return {
            "status": "healthy",
            "timestamp": asyncio.get_event_loop().time(),
            "system": {
                "gpu_available": gpu_available,
                "gpu_count": gpu_count,
                "python_version": sys.version
            }
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")

@app.post("/query", response_model=QueryResponse)
async def process_query(request: QueryRequest):
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    try:
        logger.info(f"ğŸ¤– Processing query: {request.query[:100]}...")
        
        # æ„å»ºé…ç½®
        config = {
            "query": request.query,
            "image": request.image,
            "context": request.context,
            "model": request.model,
            "type": request.type,
            "device": request.device,
            "agents": request.agents
        }
        
        # è°ƒç”¨å¤„ç†å‡½æ•°
        result = await process_request(config)
        
        # æ„å»ºå“åº”
        response = QueryResponse(
            success=True,
            answer=result.get("answer", "No response generated"),
            confidence=result.get("confidence", 0.0),
            agent_used=result.get("agent_used", "unknown"),
            processing_time=result.get("processing_time", 0.0),
            metadata=result.get("metadata", {})
        )
        
        logger.info(f"âœ… Query processed successfully, agent: {response.agent_used}")
        return response
        
    except Exception as e:
        logger.error(f"âŒ Query processing failed: {e}")
        error_response = QueryResponse(
            success=False,
            answer=f"Processing failed: {str(e)}",
            confidence=0.0,
            agent_used="error",
            processing_time=0.0,
            error=str(e)
        )
        return error_response

@app.post("/query/multimodal")
async def process_multimodal_query(
    query: str = Form(...),
    image: Optional[UploadFile] = File(None),
    context: str = Form("{}"),
    model: str = Form("Qwen/Qwen2.5-VL-7B-Instruct"),
    device: str = Form("cpu")
):
    """å¤„ç†å¤šæ¨¡æ€æŸ¥è¯¢ï¼ˆæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    try:
        logger.info(f"ğŸ–¼ï¸ Processing multimodal query: {query[:100]}...")
        
        # å¤„ç†å›¾ç‰‡
        image_data = None
        if image:
            image_bytes = await image.read()
            image_data = base64.b64encode(image_bytes).decode("utf-8")
            logger.info(f"ğŸ“· Image uploaded: {image.filename}, size: {len(image_bytes)} bytes")
        
        # è§£æä¸Šä¸‹æ–‡
        try:
            context_dict = json.loads(context)
        except json.JSONDecodeError:
            context_dict = {}
        
        # æ„å»ºè¯·æ±‚
        request = QueryRequest(
            query=query,
            image=image_data,
            context=context_dict,
            model=model,
            device=device
        )
        
        # è°ƒç”¨æŸ¥è¯¢å¤„ç†
        return await process_query(request)
        
    except Exception as e:
        logger.error(f"âŒ Multimodal query processing failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agents")
async def list_agents():
    """åˆ—å‡ºå¯ç”¨çš„æ™ºèƒ½ä½“"""
    agents = {
        "route_agent": {
            "name": "è·¯ç”±æ™ºèƒ½ä½“",
            "description": "è´Ÿè´£æŸ¥è¯¢è·¯ç”±å’Œæ™ºèƒ½ä½“é€‰æ‹©",
            "type": "routing"
        },
        "visual_analysis_agent": {
            "name": "è§†è§‰åˆ†ææ™ºèƒ½ä½“", 
            "description": "å¤„ç†å›¾åƒå’Œè§†è§‰å†…å®¹åˆ†æ",
            "type": "multimodal"
        },
        "metrics_analysis_agent": {
            "name": "æŒ‡æ ‡åˆ†ææ™ºèƒ½ä½“",
            "description": "åˆ†æç³»ç»ŸæŒ‡æ ‡å’Œæ€§èƒ½æ•°æ®",
            "type": "analysis"
        },
        "log_analysis_agent": {
            "name": "æ—¥å¿—åˆ†ææ™ºèƒ½ä½“",
            "description": "åˆ†æç³»ç»Ÿæ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯",
            "type": "analysis"
        },
        "knowledge_agent": {
            "name": "çŸ¥è¯†é—®ç­”æ™ºèƒ½ä½“",
            "description": "åŸºäºçŸ¥è¯†åº“å›ç­”æŠ€æœ¯é—®é¢˜",
            "type": "knowledge"
        },
        "comprehensive_agent": {
            "name": "ç»¼åˆåˆ†ææ™ºèƒ½ä½“",
            "description": "ç»¼åˆå¤šç§ä¿¡æ¯æºè¿›è¡Œåˆ†æ",
            "type": "comprehensive"
        },
        "retrieval_agent": {
            "name": "æ£€ç´¢å¢å¼ºæ™ºèƒ½ä½“",
            "description": "åŸºäºæ–‡æ¡£æ£€ç´¢çš„é—®ç­”",
            "type": "retrieval"
        },
        "search_agent": {
            "name": "æœç´¢æ™ºèƒ½ä½“",
            "description": "ç½‘ç»œæœç´¢å’Œä¿¡æ¯è·å–",
            "type": "search"
        }
    }
    
    return {
        "agents": agents,
        "total_count": len(agents)
    }

@app.get("/config")
async def get_config():
    """è·å–ç³»ç»Ÿé…ç½®ä¿¡æ¯"""
    try:
        config_path = project_root / "config.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return {
                "config": config,
                "config_path": str(config_path)
            }
        else:
            return {
                "error": "Configuration file not found",
                "config_path": str(config_path)
            }
    except Exception as e:
        logger.error(f"Failed to load config: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to load config: {str(e)}")

# å¯åŠ¨å‡½æ•°
def start_server(host: str = "0.0.0.0", port: int = 8080, reload: bool = False):
    """å¯åŠ¨APIæœåŠ¡å™¨"""
    print("ğŸš€ OnCallAgent API Server Starting...")
    print(f"ğŸ“ Server URL: http://{host}:{port}")
    print(f"ğŸ“– API Docs: http://{host}:{port}/docs")
    print(f"ğŸ” ReDoc: http://{host}:{port}/redoc")
    print("=" * 50)
    
    uvicorn.run(
        "src.api:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="OnCallAgent API Server")
    parser.add_argument("--host", default="0.0.0.0", help="Host address")
    parser.add_argument("--port", type=int, default=8080, help="Port number")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload")
    
    args = parser.parse_args()
    start_server(args.host, args.port, args.reload)