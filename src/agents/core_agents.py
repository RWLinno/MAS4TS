from typing import Any, Dict, List, Optional, Tuple, Union
import asyncio
import logging
import re

from .base import Agent, AgentInput, AgentOutput, AgentConfig, AgentRegistry
from ..utils.model_manager import UnifiedModelManager, ModelRequest

logger = logging.getLogger(__name__)

@AgentRegistry.register()
class RouteAgent(Agent):
    """è·¯ç”±æ™ºèƒ½ä½“ - è´Ÿè´£åˆ†ææŸ¥è¯¢å¹¶é€‰æ‹©æœ€é€‚åˆçš„æ™ºèƒ½ä½“"""
    
    def __init__(self, config: Optional[Union[Dict[str, Any], AgentConfig]] = None):
        if isinstance(config, dict):
            agent_config = AgentConfig(
                name="route_agent",
                description="è·¯ç”±æ™ºèƒ½ä½“ï¼Œè´Ÿè´£åˆ†ææŸ¥è¯¢å¹¶è·¯ç”±åˆ°åˆé€‚çš„æ™ºèƒ½ä½“",
                version="1.0.0",
                extra_params=config
            )
        else:
            agent_config = config     
        super().__init__(agent_config)
        self.raw_config = config if isinstance(config, dict) else (config.extra_params if config else {})

    def _detect_modalities(self, query: str, context: Dict[str, Any]) -> Dict[str, bool]:
        """æ£€æµ‹è¾“å…¥æ•°æ®çš„æ¨¡æ€ç‰¹å¾"""
        
        # æ£€æµ‹æŸ¥è¯¢ä¸­æ˜¯å¦æåˆ°å›¾åƒç›¸å…³å†…å®¹
        image_keywords = [
            "image", "å›¾åƒ", "å›¾ç‰‡", "picture", "photo", "ç…§ç‰‡", "screenshot", "æˆªå›¾", 
            "pic", "å›¾", "è§†è§‰", "çœ‹", "æ˜¾ç¤º", "å±•ç¤º", "img", "jpeg", "jpg", "png",
            "analyze the image", "explain the picture", "what's in the", "describe the",
            "in the picture", "in the image", "å›¾ç‰‡ä¸­", "å›¾åƒä¸­", "æˆªå›¾ä¸­"
        ]
        
        query_mentions_image = any(keyword in query.lower() for keyword in image_keywords)
        
        # æ£€æµ‹@æ–‡æ¡£å¼•ç”¨è¯­æ³•
        doc_reference_pattern = r'@([a-zA-Z0-9_-]+\.md)'
        has_doc_reference = bool(re.search(doc_reference_pattern, query))
        
        # ç½‘ç»œæœç´¢å…³é”®è¯æ£€æµ‹ï¼ˆå‚è€ƒEigentçš„æœç´¢è§¦å‘æœºåˆ¶ï¼‰
        search_keywords = [
            "search", "find", "lookup", "latest", "current", "recent", "update",
            "æœç´¢", "æŸ¥æ‰¾", "æœ€æ–°", "å½“å‰", "æœ€è¿‘", "æ›´æ–°",
            "what is", "how to", "best practice", "documentation", "tutorial",
            "ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "æœ€ä½³å®è·µ", "æ–‡æ¡£", "æ•™ç¨‹", "æŒ‡å—"
        ]
        
        # å¢å¼ºæŠ€æœ¯é—®é¢˜å’Œæ•…éšœæ£€æµ‹
        tech_problem_keywords = [
            # æŠ€æœ¯ç»„ä»¶
            "redis", "kafka", "mysql", "api", "æ¥å£", "æ•°æ®åº“", "ç¼“å­˜", "æ¶ˆæ¯é˜Ÿåˆ—",
            "æœåŠ¡", "service", "platform", "å¹³å°", "ç³»ç»Ÿ", "system",
            
            # é—®é¢˜ç±»å‹
            "é—®é¢˜", "æ•…éšœ", "error", "é”™è¯¯", "å¼‚å¸¸", "exception", "bug", "issue",
            "è¶…æ—¶", "timeout", "å»¶è¿Ÿ", "æ…¢", "latency", "slow", "å¡", "å“åº”",
            "è¿æ¥", "connection", "æ–­å¼€", "disconnect", "å¤±è´¥", "fail",
            
            # è§£å†³ç›¸å…³
            "è§£å†³", "ä¿®å¤", "fix", "æ’æŸ¥", "troubleshoot", "è¯Šæ–­", "æ€ä¹ˆåŠ", "å¦‚ä½•",
            "æ–¹æ¡ˆ", "solution", "æ¢å¤", "recovery", "å¤„ç†", "handle"
        ]
        
        # ä¸šåŠ¡é¢†åŸŸå…³é”®è¯
        business_keywords = [
            "æ¨è", "recommend", "æ•°æ®", "data", "æ¥å£", "interface", 
            "ç›‘æ§", "monitor", "å‘Šè­¦", "alert", "æ—¥å¿—", "log"
        ]
        
        has_tech_problem = any(keyword in query.lower() for keyword in tech_problem_keywords)
        has_business_context = any(keyword in query.lower() for keyword in business_keywords)
        needs_search = any(keyword in query.lower() for keyword in search_keywords)
        
        modalities = {
            "has_text": bool(query.strip()),
            "has_image": ("image" in context and context["image"] is not None) or query_mentions_image,
            "mentions_image": query_mentions_image,  # æ–°å¢ï¼šæŸ¥è¯¢ä¸­æåˆ°å›¾åƒ
            "has_actual_image": "image" in context and context["image"] is not None,  # å®é™…æœ‰å›¾åƒæ•°æ®
            "has_doc_reference": has_doc_reference,  # æ–°å¢ï¼š@æ–‡æ¡£å¼•ç”¨
            "has_tech_problem": has_tech_problem,  # æ–°å¢ï¼šæŠ€æœ¯é—®é¢˜
            "has_business_context": has_business_context,  # æ–°å¢ï¼šä¸šåŠ¡ä¸Šä¸‹æ–‡
            "needs_search": needs_search,  # æ–°å¢ï¼šéœ€è¦ç½‘ç»œæœç´¢
            "has_metrics": any(word in query.lower() for word in [
                "metrics", "æŒ‡æ ‡", "ç›‘æ§", "å›¾è¡¨", "æ•°æ®", "æ€§èƒ½", "å»¶è¿Ÿ", "å“åº”æ—¶é—´", "cpu", "memory", "disk"
            ]),
            "has_logs": any(word in query.lower() for word in [
                "log", "logs", "æ—¥å¿—", "æŠ¥é”™", "å¼‚å¸¸", "é”™è¯¯", "è­¦å‘Š", "error", "warning", "exception"
            ]),
            "needs_knowledge": any(word in query.lower() for word in [
                "what is", "ä»€ä¹ˆæ˜¯", "ä»‹ç»", "æ¦‚å¿µ", "å®šä¹‰", "åŸç†", "å†å²", "å‘å±•"
            ]) and not has_tech_problem,  # åªæœ‰çº¯çŸ¥è¯†æŸ¥è¯¢æ‰ç®—knowledge
            "needs_retrieval": has_doc_reference or has_tech_problem or has_business_context or any(word in query.lower() for word in [
                "æŸ¥æ‰¾", "æœç´¢", "æ£€ç´¢", "èµ„æ–™", "æ–‡æ¡£", "çŸ¥è¯†", "ä¿¡æ¯", "è¯¦ç»†", "å…·ä½“", "é—®é¢˜", "æ•…éšœ", "æ’æŸ¥"
            ])
        }
        return modalities

    def _select_best_agent(self, modalities: Dict[str, bool]) -> Tuple[str, str, float]:
        """æ ¹æ®æ¨¡æ€ç‰¹å¾é€‰æ‹©æœ€ä½³æ™ºèƒ½ä½“ï¼Œå‚è€ƒEigentçš„æ™ºèƒ½è·¯ç”±ç­–ç•¥"""
        
        # 1. å¦‚æœéœ€è¦ç½‘ç»œæœç´¢ï¼Œä¼˜å…ˆä½¿ç”¨SearchAgentï¼ˆå‚è€ƒEigentï¼‰
        if modalities["needs_search"]:
            return "search_agent", "æ£€æµ‹åˆ°æœç´¢éœ€æ±‚ï¼Œä½¿ç”¨ç½‘ç»œæœç´¢æ™ºèƒ½ä½“è·å–æœ€æ–°ä¿¡æ¯", 0.9
        
        # 2. å¦‚æœæœ‰@æ–‡æ¡£å¼•ç”¨ï¼Œä½¿ç”¨RetrieverAgent
        if modalities["has_doc_reference"]:
            return "retriever_agent", "æ£€æµ‹åˆ°@æ–‡æ¡£å¼•ç”¨ï¼Œä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ", 0.95
        
        # 3. å¦‚æœæœ‰å›¾åƒæˆ–æŸ¥è¯¢ä¸­æåˆ°å›¾åƒï¼Œä¼˜å…ˆè§†è§‰åˆ†æ
        if modalities["has_image"]:
            if modalities["has_actual_image"]:
                return "visual_analysis_agent", "è¯·æ±‚åŒ…å«å›¾åƒï¼Œéœ€è¦è§†è§‰åˆ†æ", 0.9
            elif modalities["mentions_image"]:
                return "visual_analysis_agent", "æŸ¥è¯¢æåˆ°å›¾åƒï¼Œéœ€è¦è§†è§‰åˆ†æï¼ˆå°†å°è¯•è‡ªåŠ¨æŸ¥æ‰¾å›¾ç‰‡ï¼‰", 0.85
        
        # 4. å¦‚æœéœ€è¦æ£€ç´¢ï¼Œä½¿ç”¨RetrieverAgent
        if modalities["needs_retrieval"]:
            return "retriever_agent", "éœ€è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£è¿›è¡Œå›ç­”", 0.85
        
        # 4. æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ä¸“ä¸šæ™ºèƒ½ä½“
        if modalities["has_metrics"]:
            return "metrics_analysis_agent", "è¯·æ±‚æ¶‰åŠæŒ‡æ ‡æˆ–ç›‘æ§æ•°æ®åˆ†æ", 0.8
        elif modalities["has_logs"]:
            return "log_analysis_agent", "è¯·æ±‚æ¶‰åŠæ—¥å¿—åˆ†æ", 0.8
        elif modalities["needs_knowledge"]:
            return "knowledge_agent", "è¯·æ±‚éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“", 0.7
        
        # 5. å¤æ‚æŸ¥è¯¢ä½¿ç”¨ç»¼åˆæ™ºèƒ½ä½“
        return "comprehensive_agent", "å¤æ‚æŸ¥è¯¢éœ€è¦ç»¼åˆåˆ†æ", 0.6

    async def execute(self, input_data: AgentInput) -> AgentOutput:
        query = input_data.query
        context = input_data.context or {}
        
        # æ£€æµ‹æ¨¡æ€ç‰¹å¾
        modalities = self._detect_modalities(query, context)
        
        # é€‰æ‹©æœ€ä½³æ™ºèƒ½ä½“
        selected_agent, reasoning, confidence = self._select_best_agent(modalities)
        
        route_result = {
            "next_agent": selected_agent,
            "reasoning": reasoning,
            "modalities": modalities,
            "confidence": confidence
        }
        
        return AgentOutput(
            result=selected_agent,
            context={"route_info": route_result},
            confidence=confidence
        )

@AgentRegistry.register()
class KnowledgeAgent(Agent):
    """çŸ¥è¯†æ™ºèƒ½ä½“ - åŸºäºé€šç”¨çŸ¥è¯†å›ç­”é—®é¢˜"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        self.model_manager = None
    
    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2-7B-Instruct")
            device_config = context.get("device_config", {"gpu_ids": [0]})
            offline_mode = context.get("offline_mode", False)
            
            self.model_manager = UnifiedModelManager(
                model_name=model_name,
                device_config=device_config,
                offline_mode=offline_mode
            )
        return self.model_manager
    
    async def execute(self, input_data: AgentInput) -> AgentOutput:
        query = input_data.query
        context = input_data.context or {}
        
        try:
            model_manager = self._get_model_manager(context)
            
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä½ çš„çŸ¥è¯†è¯¦ç»†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®ã€å®ç”¨çš„å»ºè®®ã€‚"
                },
                {
                    "role": "user",
                    "content": f"è¯·è¯¦ç»†å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}"
                }
            ]
            
            request = ModelRequest(
                messages=messages,
                max_tokens=512,
                temperature=0.7
            )
            
            response = await model_manager.generate(request)
            
            if response.success:
                return AgentOutput(
                    result=response.content,
                    context={"source": "direct_model", "rag_enabled": False},
                    confidence=0.8
                )
            else:
                return AgentOutput(
                    result=f"æ¨¡å‹ç”Ÿæˆå¤±è´¥: {response.error}",
                    confidence=0.0
                )
                
        except Exception as e:
            logger.exception(f"çŸ¥è¯†æŸ¥è¯¢å¤±è´¥: {e}")
            return AgentOutput(
                result=f"çŸ¥è¯†æŸ¥è¯¢å¤±è´¥: {str(e)}",
                confidence=0.0
            )

@AgentRegistry.register()
class VisualAnalysisAgent(Agent):
    """è§†è§‰åˆ†ææ™ºèƒ½ä½“ - å¤„ç†åŒ…å«å›¾åƒçš„æŸ¥è¯¢"""    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        print("VisualAnalysisAgent init")
        self.model_manager = None

    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        """è·å–æ¨¡å‹ç®¡ç†å™¨"""
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2.5-VL-7B-Instruct")
            self.model_manager = UnifiedModelManager.from_env(model_name, context)
        return self.model_manager
    
    async def execute(self, input_data: AgentInput) -> AgentOutput:
        query = input_data.query
        context = input_data.context or {}
        
        image_data = context.get("image")
        
        if not image_data:
            image_data = self._auto_find_image(context)
            if image_data:
                print(f"âœ“ è‡ªåŠ¨å‘ç°å›¾ç‰‡: {image_data}")
                context["image"] = image_data
            else:
                return AgentOutput(
                    result="æŸ¥è¯¢æåˆ°äº†å›¾åƒï¼Œä½†æœªæ‰¾åˆ°å›¾åƒæ•°æ®ã€‚è¯·æä¾›å›¾ç‰‡è·¯å¾„æˆ–å°†å›¾ç‰‡æ”¾åœ¨data/imgs/ç›®å½•ä¸‹ã€‚",
                    confidence=0.1
                )
        
        try:
            model_manager = self._get_model_manager(context)
            
            # å¯¹äºQwen2.5-VLï¼Œä½¿ç”¨ç®€åŒ–çš„æ¶ˆæ¯æ ¼å¼
            if isinstance(image_data, str) and (image_data.startswith('/') or image_data.startswith('./')):
                # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„
                image_content = image_data
            else:
                # å…¶ä»–æ ¼å¼ï¼Œè½¬æ¢ä¸ºåˆé€‚çš„æ ¼å¼
                image_content = self._prepare_image_content(image_data)
            
            # ä½¿ç”¨ç®€åŒ–çš„æ–‡æœ¬æ¶ˆæ¯æ ¼å¼
            messages = [
                {
                    "role": "system", 
                    "content": "You are a helpful assistant that can analyze images and answer questions about them."
                },
                {
                    "role": "user",
                    "content": f"Please analyze the image and answer: {query}"
                }
            ]
            
            request = ModelRequest(
                messages=messages,
                max_tokens=512,
                temperature=0.7,
                image=image_content
            )

            response = await model_manager.generate(request)
            if response.success:
                return AgentOutput(
                    result=response.content,
                    context={
                        "visual_analysis": response.content,
                        "image_format": "simplified",
                        "image_path": image_data if isinstance(image_data, str) else "processed_image"
                    },
                    confidence=0.9
                )
            else:
                return AgentOutput(
                    result=f"è§†è§‰åˆ†æå¤±è´¥: {response.error}",
                    confidence=0.0
                )
                
        except Exception as e:
            logger.exception(f"è§†è§‰åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return AgentOutput(
                result=f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}",
                confidence=0.0
            )
    
    def _auto_find_image(self, context: Dict[str, Any]) -> Optional[str]:
        """è‡ªåŠ¨æŸ¥æ‰¾ç›®å½•ä¸­çš„å›¾ç‰‡"""
        import os
        from pathlib import Path
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}
        
        # æœç´¢è·¯å¾„ä¼˜å…ˆçº§
        search_paths = []
        
        # 1. ä»contextä¸­è·å–å¯èƒ½çš„ç›®å½•è·¯å¾„
        global_config = context.get("global_config", {})

        # 2. æ„å»ºæœç´¢è·¯å¾„åˆ—è¡¨
        current_dir = os.getcwd()
        search_paths.extend([
            os.path.join(current_dir, "data", "imgs"),     # imagesç›®å½•
            os.path.join(current_dir, "data", "pics"),     # picsç›®å½•
            current_dir,                             # å½“å‰ç›®å½•
        ])
        
        print(f"ğŸ” æœç´¢å›¾ç‰‡è·¯å¾„: {search_paths}")
        
        for search_path in search_paths:
            if not os.path.exists(search_path):
                continue
                
            try:
                # éå†ç›®å½•ä¸­çš„æ–‡ä»¶
                for item in os.listdir(search_path):
                    file_path = os.path.join(search_path, item)
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶
                    if os.path.isfile(file_path):
                        file_ext = Path(file_path).suffix.lower()
                        if file_ext in image_extensions:
                            print(f"âœ“ æ‰¾åˆ°å›¾ç‰‡: {file_path}")
                            return file_path
                            
            except Exception as e:
                print(f"âš ï¸ æœç´¢è·¯å¾„ {search_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
        return None
    
    def _prepare_image_content(self, image_data):
        import os
        from urllib.parse import urlparse
        
        if isinstance(image_data, str):
            # æ£€æŸ¥æ˜¯å¦ä¸º URL
            if image_data.startswith(('http://', 'https://')):
                return image_data
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
            elif os.path.isfile(image_data):
                return image_data
            # å‡è®¾æ˜¯ base64 å­—ç¬¦ä¸²
            else:
                return f"data:image/jpeg;base64,{image_data}"
        else:
            # PIL Image å¯¹è±¡ï¼Œè½¬æ¢ä¸º base64
            from io import BytesIO
            import base64
            
            buffered = BytesIO()
            image_data.save(buffered, format="JPEG")
            img_bytes = buffered.getvalue()
            base64_str = base64.b64encode(img_bytes).decode('utf-8')
            return f"data:image/jpeg;base64,{base64_str}"

@AgentRegistry.register()
class MetricsAnalysisAgent(Agent):
    """æŒ‡æ ‡åˆ†ææ™ºèƒ½ä½“ - å¤„ç†ä¸ç³»ç»ŸæŒ‡æ ‡ç›¸å…³çš„æŸ¥è¯¢"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        self.model_manager = None
    
    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        """è·å–æ¨¡å‹ç®¡ç†å™¨"""
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2.5-VL-7B-Instruct")
            self.model_manager = UnifiedModelManager.from_env(model_name, context)
        return self.model_manager
    
    async def execute(self, input_data: AgentInput) -> AgentOutput:
        """æ‰§è¡ŒæŒ‡æ ‡åˆ†æ"""
        query = input_data.query
        context = input_data.context or {}
        
        try:
            model_manager = self._get_model_manager(context)
            
            messages = [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªä¸“é—¨åˆ†æç›‘æ§æŒ‡æ ‡çš„åŠ©æ‰‹ã€‚ä½ å¯ä»¥æœç´¢æŒ‡æ ‡æ•°æ®ï¼Œç”Ÿæˆå›¾è¡¨ï¼Œå¹¶æä¾›åˆ†æã€‚"
                        "è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œæä¾›è¯¦ç»†çš„æŒ‡æ ‡åˆ†æã€‚å¦‚æœéœ€è¦å…·ä½“çš„æŒ‡æ ‡æ•°æ®ï¼Œè¯·è¯´æ˜éœ€è¦æŸ¥è¯¢ä»€ä¹ˆæ ·çš„æŒ‡æ ‡ã€‚"
                    )
                },
                {
                    "role": "user",
                    "content": f"è¯·åˆ†æä»¥ä¸‹æŒ‡æ ‡ç›¸å…³çš„æŸ¥è¯¢ï¼š{query}"
                }
            ]
            
            request = ModelRequest(
                messages=messages,
                max_tokens=512,
                temperature=0.7
            )
            
            response = await model_manager.generate(request)
            
            if response.success:
                return AgentOutput(
                    result=response.content,
                    context={"metrics_analysis": response.content},
                    confidence=0.9
                )
            else:
                return AgentOutput(
                    result=f"æŒ‡æ ‡åˆ†æå¤±è´¥: {response.error}",
                    confidence=0.0
                )
                
        except Exception as e:
            logger.exception(f"æŒ‡æ ‡åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return AgentOutput(
                result=f"æŒ‡æ ‡åˆ†æå¤±è´¥: {str(e)}",
                confidence=0.0
            )

@AgentRegistry.register()
class LogAnalysisAgent(Agent):
    """æ—¥å¿—åˆ†ææ™ºèƒ½ä½“ - å¤„ç†ä¸æ—¥å¿—ç›¸å…³çš„æŸ¥è¯¢"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        self.model_manager = None
    
    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        """è·å–æ¨¡å‹ç®¡ç†å™¨"""
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2.5-VL-7B-Instruct")
            self.model_manager = UnifiedModelManager.from_env(model_name, context)
        return self.model_manager
    
    async def execute(self, input_data: AgentInput) -> AgentOutput:
        """æ‰§è¡Œæ—¥å¿—åˆ†æ"""
        query = input_data.query
        context = input_data.context or {}
        
        try:
            # è·å–æ¨¡å‹ç®¡ç†å™¨
            model_manager = self._get_model_manager(context)
            
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªä¸“é—¨åˆ†æç³»ç»Ÿæ—¥å¿—çš„åŠ©æ‰‹ã€‚ä½ å¯ä»¥æœç´¢æ—¥å¿—æ•°æ®ï¼Œè¯†åˆ«å¼‚å¸¸æ¨¡å¼ï¼Œå¹¶æä¾›åˆ†æã€‚"
                        "è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ï¼Œæä¾›è¯¦ç»†çš„æ—¥å¿—åˆ†æå»ºè®®ã€‚å¦‚æœéœ€è¦å…·ä½“çš„æ—¥å¿—æ•°æ®ï¼Œè¯·è¯´æ˜éœ€è¦æŸ¥çœ‹ä»€ä¹ˆæ ·çš„æ—¥å¿—ã€‚"
                    )
                },
                {
                    "role": "user",
                    "content": f"è¯·åˆ†æä»¥ä¸‹æ—¥å¿—ç›¸å…³çš„æŸ¥è¯¢ï¼š{query}"
                }
            ]
            
            # ç”Ÿæˆè¯·æ±‚
            request = ModelRequest(
                messages=messages,
                max_tokens=512,
                temperature=0.7
            )
            
            # è°ƒç”¨æ¨¡å‹ç®¡ç†å™¨
            response = await model_manager.generate(request)
            
            if response.success:
                return AgentOutput(
                    result=response.content,
                    context={"log_analysis": response.content},
                    confidence=0.9
                )
            else:
                return AgentOutput(
                    result=f"æ—¥å¿—åˆ†æå¤±è´¥: {response.error}",
                    confidence=0.0
                )
                
        except Exception as e:
            logger.exception(f"æ—¥å¿—åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return AgentOutput(
                result=f"æ—¥å¿—åˆ†æå¤±è´¥: {str(e)}",
                confidence=0.0
            )

@AgentRegistry.register()
class ComprehensiveAgent(Agent):
    """ç»¼åˆæ™ºèƒ½ä½“ - å¤„ç†éœ€è¦å¤šç§èƒ½åŠ›åä½œçš„å¤æ‚æŸ¥è¯¢"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        self.model_manager = None
        
        # ä¾èµ–çš„æ‰€æœ‰æ™ºèƒ½ä½“
        self.add_dependency("KnowledgeAgent")
        self.add_dependency("LogAnalysisAgent")
        self.add_dependency("MetricsAnalysisAgent")
    
    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        """è·å–æ¨¡å‹ç®¡ç†å™¨"""
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2.5-VL-7B-Instruct")
            self.model_manager = UnifiedModelManager.from_env(model_name, context)
        return self.model_manager

    async def execute(self, input_data: AgentInput) -> AgentOutput:
        """æ‰§è¡Œç»¼åˆåˆ†æ"""
        query = input_data.query
        context = input_data.context or {}
        
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥å›ç­”
            model_manager = self._get_model_manager(context)
            
            # æ„å»ºç»¼åˆåˆ†æçš„ç³»ç»Ÿæç¤º
            messages = [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªç»¼åˆåˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿å¤„ç†å¤æ‚çš„æŠ€æœ¯é—®é¢˜ã€‚"
                        "è¯·ç»¼åˆè€ƒè™‘å¤šä¸ªæ–¹é¢ï¼ˆç³»ç»Ÿç›‘æ§ã€æ—¥å¿—åˆ†æã€çŸ¥è¯†åº“ç­‰ï¼‰æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                        "å¦‚æœé—®é¢˜æ¶‰åŠå¤šä¸ªæŠ€æœ¯é¢†åŸŸï¼Œè¯·æä¾›å…¨é¢çš„åˆ†æå’Œå»ºè®®ã€‚"
                    )
                },
                {
                    "role": "user",
                    "content": f"è¯·ç»¼åˆåˆ†æä»¥ä¸‹é—®é¢˜ï¼š{query}"
                }
            ]
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒ
            image_data = context.get("image")
            request = ModelRequest(
                messages=messages,
                max_tokens=1024,
                temperature=0.7,
                image=image_data
            )
            
            response = await model_manager.generate(request)
            
            if response.success:
                return AgentOutput(
                    result=response.content,
                    context={
                        "comprehensive_analysis": response.content,
                        "analysis_type": "integrated"
                    },
                    confidence=0.8
                )
            else:
                return AgentOutput(
                    result=f"ç»¼åˆåˆ†æå¤±è´¥: {response.error}",
                    confidence=0.0
                )
                
        except Exception as e:
            logger.exception(f"ç»¼åˆåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            return AgentOutput(
                result=f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}",
                confidence=0.0
            )

@AgentRegistry.register()
class RetrieverAgent(Agent):
    """æ£€ç´¢å¢å¼ºç”Ÿæˆæ™ºèƒ½ä½“ - åŸºäºSimpleRAGæŠ€æœ¯æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ç”Ÿæˆå›ç­”"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        super().__init__(config)
        self.model_manager = None
        self.rag = None
        
        # åˆå§‹åŒ–SimpleRAG
        self._init_simple_rag()
    
    def _init_simple_rag(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿï¼ˆä¼˜å…ˆä½¿ç”¨æ•°æ®åº“é›†æˆç‰ˆæœ¬ï¼‰"""
        try:
            # Try database-integrated RAG first
            from oncall_agent.database.connection_manager import DatabaseManager
            from ..retrieval.database_rag import DatabaseRAGService
            
            # Initialize database manager (will only connect to enabled databases)
            db_config = getattr(self.config, 'extra_params', {})
            if db_config and 'database' in db_config:
                self.db_manager = DatabaseManager(db_config)
                self.rag = DatabaseRAGService(self.db_manager, db_config)
                logger.info("âœ… Database-integrated RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
                return
            else:
                logger.info("Database not configured, falling back to SimpleRAG")
        except Exception as e:
            logger.warning(f"Database RAGåˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°SimpleRAG: {e}")
        
        # Fallback to SimpleRAG
        try:
            from ..retrieval.simple_rag import SimpleRAG
            self.rag = SimpleRAG()
            logger.info("âœ… SimpleRAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"SimpleRAGåˆå§‹åŒ–å¤±è´¥: {e}")
            self.rag = None
    
    def _get_model_manager(self, context: dict) -> UnifiedModelManager:
        """è·å–æ¨¡å‹ç®¡ç†å™¨"""
        if self.model_manager is None:
            model_name = context.get("model", "Qwen/Qwen2.5-VL-7B-Instruct")
            self.model_manager = UnifiedModelManager.from_env(model_name, context)
        return self.model_manager
    
    def _build_enhanced_prompt(self, query: str, search_results) -> str:
        """æ„å»ºå¢å¼ºçš„æç¤º"""
        
        # æ£€æµ‹æ˜¯å¦æœ‰@æ–‡æ¡£å¼•ç”¨
        referenced_file = None
        if self.rag:
            referenced_file = self.rag.detect_document_reference(query)
        
        if referenced_file and search_results:
            # @æ–‡æ¡£å¼•ç”¨çš„æƒ…å†µ
            doc = search_results[0].document
            prompt = f"""ä½ éœ€è¦ä¸¥æ ¼åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚

ã€æŒ‡å®šæ–‡æ¡£ã€‘{referenced_file}
ã€æ–‡æ¡£æ ‡é¢˜ã€‘{doc.title}
ã€æ–‡æ¡£åˆ†ç±»ã€‘{doc.category}

ã€æ–‡æ¡£åŸæ–‡å†…å®¹ã€‘
{search_results[0].context}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

ã€å›ç­”è¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ æˆ–æ¨æµ‹ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æœ‰å…·ä½“çš„æ’æŸ¥æ€è·¯ã€æ•…éšœåŸå› ã€æ¢å¤æ–¹æ¡ˆï¼Œè¯·æŒ‰ç…§æ–‡æ¡£ç»“æ„ç»„ç»‡å›ç­”
3. ä¿æŒæ–‡æ¡£ä¸­çš„ä¸“ä¸šæœ¯è¯­å’Œå…·ä½“æ­¥éª¤
4. å¦‚æœæ–‡æ¡£å†…å®¹ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜å“ªäº›ä¿¡æ¯æ–‡æ¡£ä¸­æ²¡æœ‰æåŠ
5. ç”¨æ¸…æ™°çš„ç»“æ„ç»„ç»‡å›ç­”ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·"""
        
        else:
            # å¸¸è§„æ£€ç´¢çš„æƒ…å†µ
            doc_contexts = []
            for i, result in enumerate(search_results, 1):
                doc_contexts.append(f"""
ã€æ–‡æ¡£{i}ã€‘{result.document.metadata['filename']} (ç›¸å…³åº¦: {result.score:.2f})
æ ‡é¢˜: {result.document.title}
åˆ†ç±»: {result.document.category}

åŸæ–‡å†…å®¹:
{result.context}
""")
            
            contexts_text = "\n".join(doc_contexts)
            
            prompt = f"""ä½ éœ€è¦ä¸¥æ ¼åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚

{contexts_text}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

ã€å›ç­”è¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ã€æ¨æµ‹æˆ–è¡¥å……æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯
2. ä¼˜å…ˆä½¿ç”¨ç›¸å…³åº¦æœ€é«˜çš„æ–‡æ¡£å†…å®¹
3. å¦‚æœå¤šä¸ªæ–‡æ¡£éƒ½æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç»¼åˆä½¿ç”¨å¹¶æ ‡æ˜æ¥æº
4. ä¿æŒæ–‡æ¡£ä¸­çš„åŸå§‹è¡¨è¿°å’Œä¸“ä¸šæœ¯è¯­
5. å¦‚æœæ–‡æ¡£å†…å®¹ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜
6. ç”¨æ¸…æ™°çš„ç»“æ„ç»„ç»‡å›ç­”"""
        
        return prompt
    
    def _format_final_answer(self, answer: str, search_results) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆå›ç­”ï¼ŒåŒ…å«æ–‡æ¡£æ¥æº"""
        
        # æå–æ–‡æ¡£æ¥æºä¿¡æ¯
        sources = []
        for result in search_results:
            sources.append(f"ğŸ“„ {result.document.metadata['filename']} (ç›¸å…³åº¦: {result.score:.2f})")
        
        # æ„å»ºæœ€ç»ˆå›ç­”
        formatted_answer = f"""{answer}

---
ğŸ“š **å‚è€ƒæ–‡æ¡£æ¥æºï¼š**
{chr(10).join(sources)}

ğŸ’¡ **æç¤ºï¼š** æ­¤å›ç­”åŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ç”Ÿæˆï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚"""
        
        return formatted_answer
    
    async def _fallback_to_knowledge_agent(self, input_data: AgentInput) -> AgentOutput:
        """å›é€€åˆ°çŸ¥è¯†æ™ºèƒ½ä½“"""
        try:
            # åˆ›å»ºKnowledgeAgentå®ä¾‹
            knowledge_config = AgentConfig(
                name="knowledge_agent_fallback",
                description="å›é€€çŸ¥è¯†æ™ºèƒ½ä½“",
                version="1.0.0",
                extra_params=getattr(self.config, 'extra_params', {})
            )
            
            knowledge_agent = KnowledgeAgent(knowledge_config)
            result = await knowledge_agent.execute(input_data)
            
            # ä¿®æ”¹ç»“æœï¼Œæ ‡æ˜æ˜¯å›é€€æ¨¡å¼
            fallback_result = f"""ã€åŸºäºé€šç”¨çŸ¥è¯†çš„å›ç­”ã€‘

{result.result}

âš ï¸ **æ³¨æ„ï¼š** ç”±äºæœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£æˆ–æ£€ç´¢ç³»ç»Ÿä¸å¯ç”¨ï¼Œæ­¤å›ç­”åŸºäºé€šç”¨çŸ¥è¯†ç”Ÿæˆã€‚å¦‚éœ€æ›´å‡†ç¡®çš„ä¿¡æ¯ï¼Œè¯·å°è¯•ä½¿ç”¨@æ–‡æ¡£å.mdçš„æ ¼å¼å¼•ç”¨ç‰¹å®šæ–‡æ¡£ã€‚"""
            
            return AgentOutput(
                result=fallback_result,
                context={
                    **result.context,
                    "retrieval_enabled": False,
                    "fallback_mode": True
                },
                confidence=result.confidence * 0.8  # é™ä½ç½®ä¿¡åº¦
            )
            
        except Exception as e:
            logger.error(f"å›é€€åˆ°çŸ¥è¯†æ™ºèƒ½ä½“ä¹Ÿå¤±è´¥: {e}")
            return AgentOutput(
                result="æŠ±æ­‰ï¼Œæ£€ç´¢ç³»ç»Ÿå’ŒçŸ¥è¯†ç³»ç»Ÿéƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•ã€‚",
                confidence=0.0
            )

    async def execute(self, input_data: AgentInput) -> AgentOutput:
        """æ‰§è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆ"""
        query = input_data.query
        context = input_data.context or {}
        
        try:
            # æ£€æŸ¥RAGç³»ç»Ÿæ˜¯å¦å¯ç”¨
            if not self.rag:
                return await self._fallback_to_knowledge_agent(input_data)
            
            # æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–‡æ¡£
            search_results = self.rag.search_documents(query, top_k=3)
            
            if not search_results:
                logger.warning("æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå›é€€åˆ°çŸ¥è¯†æ™ºèƒ½ä½“")
                return await self._fallback_to_knowledge_agent(input_data)
            
            # æ­¥éª¤2: è·å–æ¨¡å‹ç®¡ç†å™¨
            model_manager = self._get_model_manager(context)
            
            # æ­¥éª¤3: æ„å»ºå¢å¼ºçš„æç¤º
            enhanced_prompt = self._build_enhanced_prompt(query, search_results)
            
            # æ­¥éª¤4: ç”Ÿæˆå›ç­”
            request = ModelRequest(
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
                            "é‡è¦åŸåˆ™ï¼šåªä½¿ç”¨æ–‡æ¡£ä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸è¦æ·»åŠ ã€æ¨æµ‹æˆ–ç¼–é€ ä»»ä½•å†…å®¹ã€‚"
                            "å¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜ï¼Œè€Œä¸æ˜¯è¡¥å……å…¶ä»–çŸ¥è¯†ã€‚"
                        )
                    },
                    {
                        "role": "user", 
                        "content": enhanced_prompt
                    }
                ],
                max_tokens=1024,
                temperature=0.1  # é™ä½æ¸©åº¦ï¼Œå‡å°‘åˆ›é€ æ€§å›ç­”
            )
            
            response = await model_manager.generate(request)
            
            if response.success:
                # æ„å»ºå›ç­”ï¼ŒåŒ…å«æ–‡æ¡£æ¥æºä¿¡æ¯
                final_answer = self._format_final_answer(response.content, search_results)
                
                return AgentOutput(
                    result=final_answer,
                    context={
                        "retrieval_enabled": True,
                        "documents_found": len(search_results),
                        "document_sources": [r.document.metadata['filename'] for r in search_results],
                        "confidence_boost": True,
                        "search_query": query,
                        "search_scores": [r.score for r in search_results]
                    },
                    confidence=0.95  # é«˜ç½®ä¿¡åº¦ï¼Œå› ä¸ºåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£
                )
            else:
                return await self._fallback_to_knowledge_agent(input_data)
                
        except Exception as e:
            logger.exception(f"RetrieverAgentæ‰§è¡Œå¤±è´¥: {e}")
            return await self._fallback_to_knowledge_agent(input_data)
